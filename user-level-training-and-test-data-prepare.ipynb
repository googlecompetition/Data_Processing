{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "da257aad9b04cbebc1e67e6465414e7e379fc1e9"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Fork from https://www.kaggle.com/augustmarvel/base-model-v2-user-level-solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a04a68f5edf3bcd4f18524049ac02d185fdf0e76"
   },
   "source": [
    "### This kernel is mainly made up of three parts:\n",
    "* [**1. Data loading**](#Data loading)\n",
    "* [**2. Data preprocessing**](#Data preprocessing)\n",
    "* [**3. Model building**](#Model building)\n",
    "\n",
    "###  Main of the kernel:\n",
    "*  Chunk whole of data set  by the period as such a structure: \n",
    "* [210 days of training period, 45 days of gap period, 2 months of traget perod].  \n",
    "* Aggregating data from the training period, ignoring the  gap period, getting the target from the traget period. \n",
    "* The valiation set is set to Dec-Jan which is the same monthly period  as the target peroid of the test set.\n",
    "\n",
    "### Summary:\n",
    " In this competition, the data set is so unbalanced that it's hard to say whether our solution can beat all-zeros. After doing some basic EDA, there are some conclusions are for sure: \n",
    "\n",
    "1. if a customer will pay,  the  transaction will be highly likely happened at the first month, and no longer than two months after the customer shows up in first time. \n",
    "2. the minimum of transaction revenue is no less than 1E+07.\n",
    "---\n",
    "* For the first one, our test set has a 1.5 months' gap between the traget period  which means our taget is divided into two groups: the first  is the one who has already spent no less than 45 days on thinking whether to pay. The second is the  one who has payed for partial services and is going to pay for additional services. To the first group, the customers are terrific unlikely to pay. To the second one, the customers are likely to pay much the same as they payed before. Under those conditions, my prediction of the number of people to pay is 200 or so.\n",
    "* For the second one, as we see, the prediction of our model is full of numbers less than 1E+07. But you'll get a worse score if you set those numbers to zero. Our model keeps betting wisely on minimize RMSE but the result keeps leaving away from the real numbers. \n",
    "\n",
    "### random thoughts:\n",
    "* To set a user-defined objective function, which gives a high penalty once the floor level is breached, will be good for avoiding small values.\n",
    "* Time features should be under the first priority.\n",
    "* To the second group people, if it's possible to specify them by clustering.\n",
    "* if the customers wil return after a full year of services are expired?\n",
    "* the data set is lack of some important features such as page views of user's website. To the low volume users, why do they pay the bill for advance services if the free account already meets all the needs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dddabb983cddc6cc669dfede6c3cb434a6d269cf"
   },
   "source": [
    "* Data are generated from this script : https://www.kaggle.com/qnkhuat/make-data-ready \n",
    "* Stacking part is from this script: https://www.kaggle.com/ashishpatel26/updated-bayesian-lgbm-xgb-cat-fe-kfold-cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c980fc990df8ec129a8143b9358cfc256c04eca9"
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_5.pkl', 'train_1.pkl', 'train_2.pkl', 'train_7.pkl', 'test_2.pkl', 'test_1.pkl', 'train_6.pkl', 'train_8.pkl', 'train_0.pkl', 'train_4.pkl', '__output__.json', 'train_3.pkl', 'test_0.pkl']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "\n",
    "data_root = '../input/make-data-ready'\n",
    "print(os.listdir(data_root))\n",
    "\n",
    "pd.set_option('display.max_rows',200)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "c3cc9e31f9c51f1fd66593d2fd0cb3963e880f12"
   },
   "outputs": [],
   "source": [
    "def load_data(data='train',n=2):\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(n) :\n",
    "        if data=='train':\n",
    "            if i > 8 :\n",
    "                break\n",
    "            dfpart = pd.read_pickle(pjoin(data_root,f'train_{i}.pkl'))\n",
    "        elif data=='test':\n",
    "            if i > 2 :\n",
    "                break\n",
    "            dfpart = pd.read_pickle(pjoin(data_root,f'test_{i}.pkl'))\n",
    "        df = pd.concat([df,dfpart])\n",
    "        del dfpart\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "711b2ff1d23636474cbf8cbd63ed852d4853499d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "df_train = load_data(n=9)\n",
    "df_test = load_data('test',n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3609ea5ecb4ea0a721136c3fc804b48877df40fd"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "3d05fcea733cf0d106981b1012bc9bec45535d75"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['channelGrouping', 'date', 'fullVisitorId', 'visitId', 'visitNumber',\n",
      "       'visitStartTime', 'device_browser', 'device_deviceCategory',\n",
      "       'device_isMobile', 'device_operatingSystem', 'geoNetwork_city',\n",
      "       'geoNetwork_continent', 'geoNetwork_country', 'geoNetwork_metro',\n",
      "       'geoNetwork_networkDomain', 'geoNetwork_region',\n",
      "       'geoNetwork_subContinent', 'totals_bounces', 'totals_hits',\n",
      "       'totals_newVisits', 'totals_pageviews', 'totals_sessionQualityDim',\n",
      "       'totals_timeOnSite', 'totals_totalTransactionRevenue',\n",
      "       'totals_transactionRevenue', 'totals_transactions', 'totals_visits',\n",
      "       'trafficSource_adContent',\n",
      "       'trafficSource_adwordsClickInfo.adNetworkType',\n",
      "       'trafficSource_adwordsClickInfo.gclId',\n",
      "       'trafficSource_adwordsClickInfo.isVideoAd',\n",
      "       'trafficSource_adwordsClickInfo.page',\n",
      "       'trafficSource_adwordsClickInfo.slot', 'trafficSource_campaign',\n",
      "       'trafficSource_isTrueDirect', 'trafficSource_keyword',\n",
      "       'trafficSource_medium', 'trafficSource_referralPath',\n",
      "       'trafficSource_source', 'customDimensions_index',\n",
      "       'customDimensions_value', 'Date_Year', 'Date_Month', 'Date_Week',\n",
      "       'Date_Day', 'Date_Dayofweek', 'Date_Dayofyear', 'Date_Is_month_end',\n",
      "       'Date_Is_month_start', 'Date_Is_quarter_end', 'Date_Is_quarter_start',\n",
      "       'Date_Is_year_end', 'Date_Is_year_start', 'Date_Hour'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2f385d9764874cc85395f13e16ceecabb510a828"
   },
   "source": [
    "### Drop some features and items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "68df28767f05caa0636a05ed247205f989d86e91",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# col_drop = ['Date_Year', 'Date_Month', 'Date_Week','Date_Hour','device_isMobile','device_deviceCategory',\n",
    "#        'Date_Day', 'Date_Dayofweek', 'Date_Dayofyear', 'Date_Is_month_end',\n",
    "#        'Date_Is_month_start', 'Date_Is_quarter_end', 'Date_Is_quarter_start',\n",
    "#        'Date_Is_year_end', 'Date_Is_year_start','totals_visits',\n",
    "#            'date','visitId','totals_totalTransactionRevenue','geoNetwork_city','geoNetwork_continent',\n",
    "#             'geoNetwork_metro','geoNetwork_networkDomain',\n",
    "# 'geoNetwork_region','geoNetwork_subContinent','trafficSource_adContent',\n",
    "#             'trafficSource_adwordsClickInfo.adNetworkType','trafficSource_adwordsClickInfo.gclId',\n",
    "# 'trafficSource_adwordsClickInfo.slot','trafficSource_campaign',\n",
    "#             'trafficSource_keyword','trafficSource_referralPath','trafficSource_medium',\n",
    "#             'customDimensions_value','customDimensions_index','trafficSource_source',\n",
    "#            'totals_bounces','visitNumber','totals_newVisits']\n",
    "col_drop = ['Date_Year', 'Date_Month', 'Date_Week','Date_Hour',\n",
    "       'Date_Day', 'Date_Dayofweek', 'Date_Dayofyear', 'Date_Is_month_end',\n",
    "       'Date_Is_month_start', 'Date_Is_quarter_end', 'Date_Is_quarter_start',\n",
    "       'Date_Is_year_end', 'Date_Is_year_start','totals_visits',\n",
    "            'customDimensions_value','customDimensions_index'\n",
    "           ]\n",
    "df.drop(col_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace empty fields with 'NA'\n",
    "Nulls = ['(not set)', 'not available in demo dataset', '(not provided)', \n",
    "         'unknown.unknown', '/', 'Not Socially Engaged']\n",
    "for null in Nulls:    \n",
    "    df.replace(null, 'NA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "3d908877ca829b6379b2812a2ca8fb4f6f95724f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# country_drop=df.groupby('geoNetwork_country')['totals_transactions'].sum()[df.groupby('geoNetwork_country')['totals_transactions'].sum().sort_values()<4].index.tolist()\n",
    "# df.loc[df[df.geoNetwork_country.isin(country_drop)].index,'geoNetwork_country'] = 'NaN'\n",
    "\n",
    "# df.loc[df[~df.device_browser.isin(['Edge', 'Internet Explorer', 'Firefox', 'Safari', 'Chrome'])].index,'device_browser'] = 'NaN'\n",
    "# df.loc[df[~df.device_operatingSystem.isin(['Android', 'iOS', 'Linux', 'Chrome OS', 'Windows', 'Macintosh'])].index,'device_operatingSystem'] = 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2109926 entries, 0 to 1588\n",
      "Data columns (total 38 columns):\n",
      "channelGrouping                                 object\n",
      "date                                            datetime64[ns]\n",
      "fullVisitorId                                   object\n",
      "visitId                                         int64\n",
      "visitNumber                                     int64\n",
      "visitStartTime                                  int64\n",
      "device_browser                                  object\n",
      "device_deviceCategory                           object\n",
      "device_isMobile                                 bool\n",
      "device_operatingSystem                          object\n",
      "geoNetwork_city                                 object\n",
      "geoNetwork_continent                            object\n",
      "geoNetwork_country                              object\n",
      "geoNetwork_metro                                object\n",
      "geoNetwork_networkDomain                        object\n",
      "geoNetwork_region                               object\n",
      "geoNetwork_subContinent                         object\n",
      "totals_bounces                                  int64\n",
      "totals_hits                                     int64\n",
      "totals_newVisits                                int64\n",
      "totals_pageviews                                int64\n",
      "totals_sessionQualityDim                        int64\n",
      "totals_timeOnSite                               int64\n",
      "totals_totalTransactionRevenue                  int64\n",
      "totals_transactionRevenue                       float64\n",
      "totals_transactions                             int64\n",
      "trafficSource_adContent                         object\n",
      "trafficSource_adwordsClickInfo.adNetworkType    object\n",
      "trafficSource_adwordsClickInfo.gclId            object\n",
      "trafficSource_adwordsClickInfo.isVideoAd        bool\n",
      "trafficSource_adwordsClickInfo.page             int64\n",
      "trafficSource_adwordsClickInfo.slot             object\n",
      "trafficSource_campaign                          object\n",
      "trafficSource_isTrueDirect                      bool\n",
      "trafficSource_keyword                           object\n",
      "trafficSource_medium                            object\n",
      "trafficSource_referralPath                      object\n",
      "trafficSource_source                            object\n",
      "dtypes: bool(3), datetime64[ns](1), float64(1), int64(12), object(21)\n",
      "memory usage: 585.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6c893481ff845810da8afa0b9c74f421d5040737"
   },
   "source": [
    "### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# col = 'trafficSource_adwordsClickInfo.page'\n",
    "# print(len(df[col].unique()))\n",
    "# print(df[col].mode())\n",
    "# print(df[col].describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "d57562be04b714d000cc04b9f228af5415c2fb3a"
   },
   "outputs": [],
   "source": [
    "col_lb = ['channelGrouping','device_browser', 'device_deviceCategory', 'device_operatingSystem', \n",
    "          'geoNetwork_city', 'geoNetwork_country', 'geoNetwork_metro', 'geoNetwork_networkDomain',\n",
    "          'geoNetwork_region', 'geoNetwork_continent', 'geoNetwork_subContinent',\n",
    "          'trafficSource_adContent', 'trafficSource_adwordsClickInfo.adNetworkType',\n",
    "          'trafficSource_adwordsClickInfo.gclId', 'trafficSource_adwordsClickInfo.slot',\n",
    "          'trafficSource_campaign', 'trafficSource_keyword', 'trafficSource_medium',\n",
    "          'trafficSource_referralPath', 'trafficSource_source']\n",
    "for col in col_lb:\n",
    "    lb = LabelEncoder()\n",
    "    df[col]=lb.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "daa3c2dd554b4892cc8f797b4151f9c673238a5f"
   },
   "source": [
    "### Features to user level\n",
    "There is also a feature called time_diff, which is directly coded in generating part. And this time- relative feature really works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_mode = ['channelGrouping', 'device_browser', 'device_deviceCategory', \n",
    "           'geoNetwork_networkDomain', 'geoNetwork_city', 'device_operatingSystem', 'geoNetwork_metro', 'geoNetwork_region',\n",
    "          'geoNetwork_country', 'geoNetwork_continent', \n",
    "           'trafficSource_adwordsClickInfo.gclId', \n",
    "           'trafficSource_keyword', 'trafficSource_medium', 'trafficSource_referralPath', 'trafficSource_source',\n",
    "          'totals_sessionQualityDim', 'trafficSource_isTrueDirect', 'totals_newVisits', 'device_isMobile',\n",
    "          'trafficSource_adwordsClickInfo.isVideoAd', 'trafficSource_adwordsClickInfo.page']\n",
    "to_sum = ['totals_timeOnSite', 'totals_pageviews', 'totals_hits', 'totals_totalTransactionRevenue', 'totals_transactions']\n",
    "to_min = ['totals_timeOnSite', 'totals_pageviews', 'totals_hits', 'totals_totalTransactionRevenue', 'totals_transactions']\n",
    "to_max = ['totals_timeOnSite', 'totals_pageviews', 'totals_hits', 'totals_totalTransactionRevenue', 'totals_transactions',\n",
    "          'visitNumber']\n",
    "to_mean = ['totals_timeOnSite', 'totals_pageviews', 'totals_hits', 'totals_totalTransactionRevenue', 'totals_transactions',\n",
    "           'trafficSource_isTrueDirect', 'totals_newVisits', 'device_isMobile', 'trafficSource_adwordsClickInfo.isVideoAd',\n",
    "          'trafficSource_adwordsClickInfo.page', 'totals_sessionQualityDim']\n",
    "to_std = ['totals_timeOnSite', 'totals_pageviews', 'totals_hits', 'totals_totalTransactionRevenue', 'totals_transactions']\n",
    "to_skew = ['totals_timeOnSite', 'totals_pageviews', 'totals_hits', 'totals_totalTransactionRevenue', 'totals_transactions']\n",
    "\n",
    "to_time = 'visitStartTime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "08422247faa12dfb05b56eb5c968fc17b61dcfdf"
   },
   "outputs": [],
   "source": [
    "# to_median = ['channelGrouping','device_browser','device_operatingSystem',\n",
    "#              'geoNetwork_country','trafficSource_adwordsClickInfo.isVideoAd',\n",
    "#              'trafficSource_isTrueDirect','trafficSource_adwordsClickInfo.page']\n",
    "# to_sum =['totals_hits','totals_pageviews','totals_timeOnSite','totals_transactionRevenue', 'totals_transactions']\n",
    "# to_mean =['totals_hits','totals_pageviews','totals_sessionQualityDim']\n",
    "# to_std = ['totals_hits','totals_pageviews']\n",
    "# to_time = 'visitStartTime'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "73bfce7889aee0d47dfa4329f5467b886d45e501"
   },
   "source": [
    "### Time period\n",
    "* the training set has a 46 days gap to its target set that is same as the test set \n",
    "* the training set has almost the same duration as the test set\n",
    "* the valiation set is set to Dec-Jan which is the same monthly period  as the target peroid of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "4f462ee9657626056b3d37ec053f96e3759dda46"
   },
   "outputs": [],
   "source": [
    "# target_period = pd.date_range(start='2016-08-01',end='2018-12-01', freq='2MS')\n",
    "# train_period = target_period.to_series().shift(periods=-210, freq='d',axis= 0)\n",
    "# time_to = train_period[train_period.index>np.datetime64('2016-08-01')].astype('int')//10**9\n",
    "# time_end = target_period.to_series().shift(periods=-45, freq='d',axis= 0)[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_period = pd.date_range(start='2016-08-01',end='2018-12-01', freq='2MS')\n",
    "train_period = target_period.to_series().shift(periods=-8, freq='m').shift(periods=1, freq='d',axis= 0)\n",
    "time_to = train_period[train_period.index>np.datetime64('2016-08-01')].astype('int')//10**9\n",
    "time_end = target_period.to_series().shift(periods=-46, freq='d',axis= 0)[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2016-08-01', '2016-10-01', '2016-12-01', '2017-02-01',\n",
      "               '2017-04-01', '2017-06-01', '2017-08-01', '2017-10-01',\n",
      "               '2017-12-01', '2018-02-01', '2018-04-01', '2018-06-01',\n",
      "               '2018-08-01', '2018-10-01', '2018-12-01'],\n",
      "              dtype='datetime64[ns]', freq='2MS')\n",
      "2016-01-01   2016-08-01\n",
      "2016-03-01   2016-10-01\n",
      "2016-05-01   2016-12-01\n",
      "2016-07-01   2017-02-01\n",
      "2016-09-01   2017-04-01\n",
      "2016-11-01   2017-06-01\n",
      "2017-01-01   2017-08-01\n",
      "2017-03-01   2017-10-01\n",
      "2017-05-01   2017-12-01\n",
      "2017-07-01   2018-02-01\n",
      "2017-09-01   2018-04-01\n",
      "2017-11-01   2018-06-01\n",
      "2018-01-01   2018-08-01\n",
      "2018-03-01   2018-10-01\n",
      "2018-05-01   2018-12-01\n",
      "Freq: 2MS, dtype: datetime64[ns]\n",
      "2016-09-01    1491004800\n",
      "2016-11-01    1496275200\n",
      "2017-01-01    1501545600\n",
      "2017-03-01    1506816000\n",
      "2017-05-01    1512086400\n",
      "2017-07-01    1517443200\n",
      "2017-09-01    1522540800\n",
      "2017-11-01    1527811200\n",
      "2018-01-01    1533081600\n",
      "2018-03-01    1538352000\n",
      "2018-05-01    1543622400\n",
      "Freq: 2MS, dtype: int64\n",
      "2017-02-14   2017-04-01\n",
      "2017-04-16   2017-06-01\n",
      "2017-06-16   2017-08-01\n",
      "2017-08-16   2017-10-01\n",
      "2017-10-16   2017-12-01\n",
      "2017-12-17   2018-02-01\n",
      "2018-02-14   2018-04-01\n",
      "2018-04-16   2018-06-01\n",
      "2018-06-16   2018-08-01\n",
      "2018-08-16   2018-10-01\n",
      "2018-10-16   2018-12-01\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(target_period)\n",
    "print(train_period)\n",
    "print(time_to)\n",
    "print(time_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0a0d781e54279f9ed2035b6f83ea0597e01d4139"
   },
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_mode(x):\n",
    "#     return max(map(lambda val: (x.count(val), val), set(x)))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to calculate mode, faster than pandas built in mode function\n",
    "from collections import defaultdict\n",
    "def cal_mode(a):\n",
    "    d = defaultdict(int)\n",
    "    for i in a:\n",
    "        d[i] += 1\n",
    "    return sorted(d.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
    "\n",
    "# lVals = [1,2,3,1,2,1,1,1,3,2,2,1]\n",
    "# print (cal_mode(lVals))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401589, 54)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "b559aa5ad7ba5edd36f787b7d6877e5595960507",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 49s, sys: 4.32 s, total: 4min 53s\n",
      "Wall time: 4min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user_x = df.iloc[df_train.shape[0]:,:]\n",
    "i = len(time_to) - 1 \n",
    "# user_x = df[(df.visitStartTime>=(time_to.index.astype('int')//10**9)[i]) & (df.visitStartTime<(time_end.index.astype('int')//10**9)[i])]\n",
    "test_x = user_x.groupby('fullVisitorId').agg(\n",
    "    channelGrouping = ('channelGrouping', lambda x: cal_mode(x)),\n",
    "    device_browser = ('device_browser', lambda x: cal_mode(x)),\n",
    "    deviceCategory = ('device_deviceCategory', lambda x: cal_mode(x)), \n",
    "    operatingSystem = ('device_operatingSystem', lambda x: cal_mode(x)), \n",
    "    networkDomain = ('geoNetwork_networkDomain', lambda x: cal_mode(x)), \n",
    "    city = ('geoNetwork_city', lambda x: cal_mode(x)),\n",
    "    metro = ('geoNetwork_metro', lambda x: cal_mode(x)),\n",
    "    region = ('geoNetwork_region', lambda x: cal_mode(x)),\n",
    "    country = ('geoNetwork_country', lambda x: cal_mode(x)),\n",
    "    continent = ('geoNetwork_continent', lambda x: cal_mode(x)),\n",
    "    adwordsClickInfo_gclId = ('trafficSource_adwordsClickInfo.gclId', lambda x: cal_mode(x)),\n",
    "    keyword = ('trafficSource_keyword', lambda x: cal_mode(x)),\n",
    "    medium = ('trafficSource_medium', lambda x: cal_mode(x)),\n",
    "    referralPath = ('trafficSource_referralPath', lambda x: cal_mode(x)),\n",
    "    source = ('trafficSource_source', lambda x: cal_mode(x)),\n",
    "    isTrueDirect = ('trafficSource_isTrueDirect', lambda x: cal_mode(x)),\n",
    "    isVideoAd = ('trafficSource_adwordsClickInfo.isVideoAd', lambda x: cal_mode(x)),\n",
    "    adwordsClickInfo_page = ('trafficSource_adwordsClickInfo.page', lambda x: cal_mode(x)),\n",
    "    totals_sessionQualityDim = ('totals_sessionQualityDim', lambda x: cal_mode(x)),\n",
    "    newVisits = ('totals_newVisits', lambda x: cal_mode(x)),\n",
    "    isMobile = ('device_isMobile', lambda x: cal_mode(x))\n",
    ")\n",
    "\n",
    "test_x = pd.concat([test_x,\n",
    "                     user_x.groupby('fullVisitorId')['visitStartTime'].agg(['min','max']).add_suffix('_time').sub(time_to.values[i]).abs(),\n",
    "                     user_x.groupby('fullVisitorId')['visitStartTime'].apply(lambda x: x.max() -x.min()).rename('time_diff'),\n",
    "                     user_x.groupby('fullVisitorId')[to_sum].sum().add_suffix('_sum'),\n",
    "                     user_x.groupby('fullVisitorId')[to_mean].mean().add_suffix('_mean'),\n",
    "                     user_x.groupby('fullVisitorId')[to_min].min().add_suffix('_min'),\n",
    "                     user_x.groupby('fullVisitorId')[to_max].max().add_suffix('_max'),\n",
    "                     # user_x.groupby('fullVisitorId')[to_skew].skew().add_suffix('_skew'),\n",
    "                     user_x.groupby('fullVisitorId')[to_std].std(ddof=0).add_suffix('_std')], axis=1).reset_index()\n",
    "\n",
    "test_x['month'] = str(time_end.dt.month[i])\n",
    "test_x['year'] = str(time_end.dt.year[i])\n",
    "\n",
    "test_x.to_pickle('test_clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fa3d17404b1de64779d970d0649feb95fbc5df82"
   },
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1491004800\n",
      "1 1496275200\n",
      "2 1501545600\n",
      "3 1506816000\n",
      "4 1512086400\n",
      "5 1517443200\n",
      "6 1522540800\n",
      "7 1527811200\n",
      "8 1533081600\n",
      "CPU times: user 50min 49s, sys: 46.4 s, total: 51min 35s\n",
      "Wall time: 51min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "blocks = 9\n",
    "\n",
    "for i in range(blocks):\n",
    "    print(i, time_to[i])\n",
    "    user_x = df[(df.visitStartTime>=(time_to.index.astype('int')//10**9)[i]) & (df.visitStartTime<(time_end.index.astype('int')//10**9)[i])]\n",
    "    user_y = df[(df.visitStartTime>=time_end.values[i].astype('int')//10**9) & (df.visitStartTime<time_end.values[i+1].astype('int')//10**9)]\n",
    "    \n",
    "    train_x = user_x.groupby('fullVisitorId').agg(\n",
    "        channelGrouping = ('channelGrouping', lambda x: cal_mode(x)),\n",
    "        device_browser = ('device_browser', lambda x: cal_mode(x)),\n",
    "        deviceCategory = ('device_deviceCategory', lambda x: cal_mode(x)), \n",
    "        operatingSystem = ('device_operatingSystem', lambda x: cal_mode(x)), \n",
    "        networkDomain = ('geoNetwork_networkDomain', lambda x: cal_mode(x)), \n",
    "        city = ('geoNetwork_city', lambda x: cal_mode(x)),\n",
    "        metro = ('geoNetwork_metro', lambda x: cal_mode(x)),\n",
    "        region = ('geoNetwork_region', lambda x: cal_mode(x)),\n",
    "        country = ('geoNetwork_country', lambda x: cal_mode(x)),\n",
    "        continent = ('geoNetwork_continent', lambda x: cal_mode(x)),\n",
    "        adwordsClickInfo_gclId = ('trafficSource_adwordsClickInfo.gclId', lambda x: cal_mode(x)),\n",
    "        keyword = ('trafficSource_keyword', lambda x: cal_mode(x)),\n",
    "        medium = ('trafficSource_medium', lambda x: cal_mode(x)),\n",
    "        referralPath = ('trafficSource_referralPath', lambda x: cal_mode(x)),\n",
    "        source = ('trafficSource_source', lambda x: cal_mode(x)),\n",
    "        isTrueDirect = ('trafficSource_isTrueDirect', lambda x: cal_mode(x)),\n",
    "        isVideoAd = ('trafficSource_adwordsClickInfo.isVideoAd', lambda x: cal_mode(x)),\n",
    "        adwordsClickInfo_page = ('trafficSource_adwordsClickInfo.page', lambda x: cal_mode(x)),\n",
    "        totals_sessionQualityDim = ('totals_sessionQualityDim', lambda x: cal_mode(x)),\n",
    "        newVisits = ('totals_newVisits', lambda x: cal_mode(x)),\n",
    "        isMobile = ('device_isMobile', lambda x: cal_mode(x))\n",
    "    )\n",
    "    \n",
    "    train_x = pd.concat([train_x,\n",
    "                     user_x.groupby('fullVisitorId')['visitStartTime'].agg(['min','max']).add_suffix('_time').sub(time_to.values[i]).abs(),\n",
    "                     user_x.groupby('fullVisitorId')['visitStartTime'].apply(lambda x: x.max() -x.min()).rename('time_diff'),\n",
    "                     user_x.groupby('fullVisitorId')[to_sum].sum().add_suffix('_sum'),\n",
    "                     user_x.groupby('fullVisitorId')[to_mean].mean().add_suffix('_mean'),\n",
    "                     user_x.groupby('fullVisitorId')[to_min].min().add_suffix('_min'),\n",
    "                     user_x.groupby('fullVisitorId')[to_max].max().add_suffix('_max'),\n",
    "                     # user_x.groupby('fullVisitorId')[to_skew].skew().add_suffix('_skew'),\n",
    "                     user_x.groupby('fullVisitorId')[to_std].std(ddof=0).add_suffix('_std')], axis=1).reset_index()\n",
    "    \n",
    "    train_x['month'] = str(time_end.dt.month[i])\n",
    "    train_x['year'] = str(time_end.dt.year[i])\n",
    "    \n",
    "    merged = train_x.merge(user_y.groupby('fullVisitorId')['totals_transactionRevenue'].sum().reset_index(),\\\n",
    "                          how='left', on='fullVisitorId')\n",
    "    \n",
    "    user_ret = set(user_y['fullVisitorId'])\n",
    "    merged['ret'] = merged['fullVisitorId'].isin(user_ret)\n",
    "    \n",
    "    merged.to_pickle('train_clean' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      df_train:  2.6 GiB\n",
      "                            df: 722.1 MiB\n",
      "                       df_test: 622.1 MiB\n",
      "                        merged: 221.5 MiB\n",
      "                       train_x: 215.6 MiB\n",
      "                        test_x: 176.1 MiB\n",
      "                        user_x: 171.0 MiB\n",
      "                        user_y: 46.0 MiB\n",
      "                      user_ret:  4.0 MiB\n",
      "                           _ii:  3.2 KiB\n"
     ]
    }
   ],
   "source": [
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
